{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[UAM-DL4IP] Image Data Augmentation (1).ipynb","provenance":[{"file_id":"1nW7jxYkT74YZUhEUvGsyX1bnXF4H8r9c","timestamp":1603444201029},{"file_id":"1yjG55QygzkaoiceQopm740t480rkau7b","timestamp":1603042855274},{"file_id":"1WdikkQea7qlZ_n5HmbSgT5iZ9Glqy-iw","timestamp":1601887273043}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"SG4KgPaT382H"},"source":["# Image Classification with PyTorch: Image Data Augmentation\n","\n","[Pablo Carballeira] (http://dymas.ii.uam.es/webvpu/gti/user/186/), Escuela Politecnica Superior, Universidad Aut√≥noma de Madrid.\n","\n","Parts of this code have been adapted from then work of Kevin McGuinness (http://www.eeng.dcu.ie/~mcguinne/), School of Electronic Engineering, Dublin City University, Ben Trevett (https://github.com/bentrevett), Heriot-Watt University, and Dhruvil Karani (https://github.com/DhruvilKarani)\n","\n","You can find documentation about working in Colab here (https://colab.research.google.com/notebooks/intro.ipynb)\n","\n","----\n","In this lab assignment, you will observe the effect of different common image data augmentation techniques. In the next part of the assignment (using a different notebook), you will evaluate if these techniques can improve the learning process of a network \n","\n"]},{"cell_type":"markdown","metadata":{"id":"aCbjIri12lnc"},"source":["# Instructions\n","\n","Anywhere you see a **???** in the code below, fill in in with the correct code."]},{"cell_type":"markdown","metadata":{"id":"yeKbwuNT2lne"},"source":["# Import packages\n","\n","\n","Find the PyTorch docs at https://pytorch.org/docs/stable/index.html \n","\n","Tutorials: https://pytorch.org/tutorials/"]},{"cell_type":"code","metadata":{"id":"hNBQ-hgC4DwD"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn.metrics as metrics\n","from sklearn import decomposition\n","from sklearn import manifold\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","\n","from torchvision.datasets.utils import download_file_from_google_drive\n","import torchvision.datasets as datasets\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","import PIL \n","from PIL import Image\n","from torchvision.datasets import CIFAR10 \n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","import sys \n","import os \n","import copy\n","import random\n","import time\n","\n","import seaborn as sns \n","from collections import Counter \n","\n","# sys.path.append(\"../models\") \n","# from models.resnet import ResNet\n","\n","from torch.autograd import Variable\n","import seaborn as sns\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-MGvs0jJ0JgA"},"source":["# Enable GPU acceleration\n","\n","Open to the Edit menu and select *Notebook settings* and check that *GPU* is selected under hardware accelerator.\n"]},{"cell_type":"code","metadata":{"id":"2OSN5zLGLxkF"},"source":["# make sure to enable GPU acceleration!\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1FcvzjWq-0xs"},"source":["We set the random seed so all of our experiments can be reproduced."]},{"cell_type":"code","metadata":{"id":"QfZxvR09IafJ"},"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ck_jtcQuPKGQ"},"source":["# Image augmentation techniques on CIFAR10: examples \n","\n","Here we will observe the effect of applying different transformations to the images of the CIFAR10 dataset an see the results in some sample images "]},{"cell_type":"markdown","metadata":{"id":"d3FySONT15Jf"},"source":["## Example of transformation definition\n","\n","Here we show the effect of applying horizontal flipping and random cropping (two transforms that we have used in the previous lab session). Here,  `RandomHorizontalFlip` flips the image horizontally with a probability of `0.5`. `RandomCrop` is used to padd the image with 4 pixels all around the image, and then take a random crop of 32x32 pixels. Note that the way to apply `RandomCrop` is slightly different to the previous sccript (resizing + cropping)  "]},{"cell_type":"code","metadata":{"id":"Wrn9NYDHPJbe"},"source":["example_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m2z7k90qwBmn"},"source":["## Load the dataset applying the transformation\n"]},{"cell_type":"code","metadata":{"id":"6WexorrOwDxq"},"source":["# labels of the CIFAR10 dataset\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# dataset download\n","cifar10_valid = CIFAR10(root = \"/data\", train= False, download = True, transform=example_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Sl9tT_Jnym0"},"source":["print(f'train set is', ' x '.join(str(x) for x in cifar10_valid.data.shape))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LJcHILdKx62I"},"source":["## Let us show some of the modified training images.\n"]},{"cell_type":"markdown","metadata":{"id":"B116RM3EPV6_"},"source":["Auxiliary functions to show a set of transformed images and their labels"]},{"cell_type":"code","metadata":{"id":"gVDM7PTCswBx"},"source":["def normalize_image(image):\n","    image_min = image.min()\n","    image_max = image.max()\n","    image.clamp_(min = image_min, max = image_max)\n","    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVwZrsXpcUSB"},"source":["def plot_images(images, labels, classes):\n","\n","    n_images = len(images)\n","\n","    rows = int(np.sqrt(n_images))\n","    cols = int(np.sqrt(n_images))\n","\n","    fig = plt.figure(figsize = (8, 8))\n","\n","    for i in range(rows*cols):\n","\n","        ax = fig.add_subplot(rows, cols, i+1)\n","        \n","        image = images[i]\n","        image = normalize_image(image)\n","\n","        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n","        ax.set_title(classes[labels[i]])\n","        ax.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MdJ7TV2CPixw"},"source":["Let's show a set of images. By running the following cell several times, you can check that several exexutions of the code will produce different transformations. Transformations are applied with a given probbilty each time the CIFAR10 class is called."]},{"cell_type":"code","metadata":{"id":"A6piM5oUcZIY"},"source":["N_IMAGES = 16\n","\n","images, labels = zip(*[(image, label) for image, label in \n","                           [cifar10_valid[i] for i in range(N_IMAGES)]])\n","classes = cifar10_valid.classes\n","plot_images(images, labels, classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IAOO9il11iw7"},"source":["## Rotation\n"]},{"cell_type":"code","metadata":{"id":"ZocuBkqo1hkh"},"source":["# define a transformation to rotate the images a random angle, betwen -30 and 30 degrees.\n","# Use the bilinear interpolation for image resampling\n","???\n","\n","cifar10_valid = CIFAR10(root = \"/data\", train=False, download = True, transform=valid_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUuJYLKuRlxE"},"source":["N_IMAGES = 16\n","\n","images, labels = zip(*[(image, label) for image, label in \n","                           [cifar10_valid[i] for i in range(N_IMAGES)]])\n","classes = cifar10_valid.classes\n","plot_images(images, labels, classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UhXbga7P62vY"},"source":["## Random Erasing"]},{"cell_type":"code","metadata":{"id":"63NRaFtW62vZ"},"source":["# define the transformation to erase a random square patch of all images,\n","# and replace it with a mid-gray patch. The erased patch must be between 2% and 25% of the image size   \n","???\n","\n","cifar10_valid = CIFAR10(root = \"/data\", train=False, download = True, transform=valid_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r60Fl3cMTNNY"},"source":["N_IMAGES = 16\n","\n","images, labels = zip(*[(image, label) for image, label in \n","                           [cifar10_valid[i] for i in range(N_IMAGES)]])\n","classes = cifar10_valid.classes\n","plot_images(images, labels, classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ldoh7aIsEY8Q"},"source":["## Color Jitter"]},{"cell_type":"code","metadata":{"id":"TfZ-wRYTEY8R"},"source":["# define the transformation to apply color jitter to all images. The parameters of the transformation are: \n","# brightness=0.3, contrast=0.3, saturation=0.2, hue=0.2    \n","???\n","\n","cifar10_valid = CIFAR10(root = \"/data\", train=False, download = True, transform=valid_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFD4Tq9WY4Ei"},"source":["N_IMAGES = 16\n","\n","images, labels = zip(*[(image, label) for image, label in \n","                           [cifar10_valid[i] for i in range(N_IMAGES)]])\n","classes = cifar10_valid.classes\n","plot_images(images, labels, classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YHhtGZ78-1Dz"},"source":["## Five Crops at test time\n","\n","We will also try an image transformation that is used at inference time.  Instead of obtaining class scores from a single test image, class scores can be averaged over the scores obtained drom slightly different inputs (image crops)\n"]},{"cell_type":"code","metadata":{"id":"6JcgSMQW-vm0"},"source":["\n","# Resize the input image to 40x40 pixels (using bilinear interpolation) and use the FiveCrop function to extract \n","# five crops from the resized image. Warning: Each input image generates 5 images. Therefore you have to change the way to convert inmages to Tensors, and the normalization\n","# Check the FiveCrop help to learn how to do it\n","???\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSageEf_-vm3"},"source":["# test loader\n","cifar10_test = CIFAR10(root = \"/data\", train=False, download = True, transform = test_crops_transform)\n","test_loader = torch.utils.data.DataLoader(cifar10_test, batch_size=5, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98oQqHyOb6PZ"},"source":["def plot_only_images(images):\n","\n","    n_images = len(images)\n","\n","    rows = int(np.sqrt(n_images))\n","    cols = int(np.sqrt(n_images))\n","\n","    fig = plt.figure(figsize = (8, 8))\n","\n","    for i in range(rows*cols):\n","\n","        ax = fig.add_subplot(rows, cols, i+1)\n","        \n","        image = images[i]\n","        image = normalize_image(image)\n","\n","        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n","        ax.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Tdc96Zq-vm_"},"source":["# get some random training images\n","dataiter = iter(test_loader)\n","images, labels = dataiter.next()\n","bs, ncrops, c, h, w = images.size()\n","\n","images = images.view(-1, c, h, w)\n","\n","# show images\n","plot_only_images(images)"],"execution_count":null,"outputs":[]}]}